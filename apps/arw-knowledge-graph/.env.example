# LLM API Configuration
# Copy this file to .env and fill in your API keys

# OpenAI Configuration
OPENAI_API_KEY=sk-...

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-...

# LLM Provider Selection
# Options: openai, anthropic
LLM_PROVIDER=openai

# Model Selection
# OpenAI models: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Anthropic models: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
LLM_MODEL=gpt-4

# Batch Processing Configuration
LLM_BATCH_SIZE=50
LLM_MAX_CONCURRENT=5

# Caching Configuration
LLM_CACHE_ENABLED=true

# Rate Limiting
LLM_RATE_LIMIT_PER_MINUTE=60

# Neo4j Configuration (from Phase 1)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password_here

# Logging Configuration
LOG_LEVEL=INFO
