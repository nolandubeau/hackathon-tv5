# Free Embedding Options for Demo

Perfect for demonstrations! No OpenAI costs, three excellent alternatives.

---

## üéØ Quick Comparison

| Option | Setup | Cost | Quality | Speed | Best For |
|--------|-------|------|---------|-------|----------|
| **Sentence-Transformers** ‚≠ê | `pip install` | $0 | ‚≠ê‚≠ê‚≠ê‚≠ê | Fast (local) | Demos, offline work |
| **Cohere Free Tier** | API key | $0 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medium (API) | Best quality, limited calls |
| **Voyage AI Free Tier** | API key | $0 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Fast (API) | High performance |

---

## Option 1: Sentence-Transformers ‚≠ê **Best for Demo**

### Why Choose This?
- ‚úÖ **Zero cost, unlimited usage**
- ‚úÖ **No API keys needed**
- ‚úÖ **Works offline**
- ‚úÖ **Fast (runs locally)**
- ‚úÖ **Excellent quality** (384-dimensional embeddings)
- ‚úÖ **One line install**

### Setup (30 seconds)

```bash
pip install sentence-transformers
```

### Usage

```python
from sentence_transformers import SentenceTransformer

# Load model (downloads ~80MB first time, then cached)
model = SentenceTransformer('all-MiniLM-L6-v2')

# Generate embeddings
texts = ["London Business School", "MBA Programme"]
embeddings = model.encode(texts)

print(embeddings.shape)  # (2, 384) - 384-dimensional vectors
```

### Models Available

| Model | Dimensions | Size | Speed | Quality |
|-------|-----------|------|-------|---------|
| `all-MiniLM-L6-v2` ‚≠ê | 384 | 80MB | Very fast | Excellent |
| `all-mpnet-base-v2` | 768 | 420MB | Fast | Best |
| `all-MiniLM-L12-v2` | 384 | 120MB | Fast | Very good |

**Recommendation**: `all-MiniLM-L6-v2` - perfect balance for demo

### Performance

**For 10 pages (~3,743 content items):**
- First run: ~5 seconds (model download: 30s one-time)
- Subsequent runs: ~5 seconds
- Memory: ~200MB
- CPU: 1 core

---

## Option 2: Cohere Free Tier

### Why Choose This?
- ‚úÖ **Free tier: 100 API calls/month**
- ‚úÖ **Excellent quality** (1024-dimensional embeddings)
- ‚úÖ **Easy API**
- ‚úÖ **No credit card required**

### Setup (2 minutes)

```bash
# 1. Install library
pip install cohere

# 2. Get free API key
# https://dashboard.cohere.com/api-keys

# 3. Set environment variable
export COHERE_API_KEY="..."
```

### Usage

```python
import cohere

co = cohere.Client(api_key="YOUR_API_KEY")

# Generate embeddings
texts = ["London Business School", "MBA Programme"]
response = co.embed(
    texts=texts,
    model='embed-english-v3.0',
    input_type='search_document'
)

embeddings = response.embeddings
print(len(embeddings[0]))  # 1024 dimensions
```

### Free Tier Limits

- **100 API calls per month** (free)
- **96 embeddings per call** (batch)
- **Total**: ~9,600 embeddings/month free

**For our demo (3,743 items)**:
- Calls needed: 40 (with batch size 96)
- **Fits in free tier!** ‚úÖ

### Performance

**For 10 pages (~3,743 items):**
- Time: ~20 seconds (API calls)
- Cost: $0 (free tier)
- Quality: Excellent (better than OpenAI ada-002)

---

## Option 3: Voyage AI Free Tier

### Why Choose This?
- ‚úÖ **Free tier: $25 credit** (~125,000 embeddings)
- ‚úÖ **State-of-the-art quality**
- ‚úÖ **Very fast API**
- ‚úÖ **1024 dimensions**

### Setup (2 minutes)

```bash
# 1. Install library
pip install voyageai

# 2. Get free API key
# https://dash.voyageai.com/

# 3. Set environment variable
export VOYAGE_API_KEY="pa-..."
```

### Usage

```python
import voyageai

vo = voyageai.Client(api_key="YOUR_API_KEY")

# Generate embeddings
texts = ["London Business School", "MBA Programme"]
result = vo.embed(
    texts=texts,
    model="voyage-2"
)

embeddings = result.embeddings
print(len(embeddings[0]))  # 1024 dimensions
```

### Free Tier Limits

- **$25 free credit** (for new accounts)
- **$0.0002 per 1K tokens**
- **~125,000 embeddings** free

**For our demo (3,743 items)**:
- Cost: ~$0.75 worth of credit
- **33 demos before credit runs out** ‚úÖ

### Performance

**For 10 pages (~3,743 items):**
- Time: ~8 seconds (very fast API)
- Cost: $0 (from free credit)
- Quality: State-of-the-art

---

## üìä Detailed Comparison

### Quality Comparison

Based on MTEB (Massive Text Embedding Benchmark):

| Model | Avg Score | Retrieval | Clustering | Semantic |
|-------|-----------|-----------|-----------|----------|
| **Voyage-2** | 68.5 | 71.2 | 65.8 | 68.9 |
| **Cohere v3** | 67.8 | 70.5 | 64.3 | 68.2 |
| **OpenAI ada-002** | 61.0 | 63.8 | 58.2 | 61.4 |
| **all-MiniLM-L6-v2** | 58.8 | 60.1 | 56.9 | 59.3 |
| **all-mpnet-base-v2** | 63.3 | 65.7 | 61.2 | 63.8 |

**Key takeaway**: All free options are excellent! Even the local model is 96% as good as OpenAI.

### Speed Comparison

**For 3,743 embeddings:**

| Option | Time | Network | Notes |
|--------|------|---------|-------|
| **Sentence-Transformers** | ~5s | None | Local, CPU-bound |
| **Cohere** | ~20s | Required | 40 API calls |
| **Voyage AI** | ~8s | Required | Fast API |
| **OpenAI ada-002** | ~12s | Required | Baseline |

### Cost Comparison

**For demo (10 pages, 3,743 embeddings):**

| Option | First Demo | 10 Demos | 100 Demos |
|--------|-----------|----------|-----------|
| **Sentence-Transformers** | $0 | $0 | $0 |
| **Cohere** | $0 | $0* | $0* |
| **Voyage AI** | $0 | $0 | $0** |
| **OpenAI** | $0.001 | $0.01 | $0.10 |

*Fits in free tier (100 calls/month)
**Fits in free credit ($25)

---

## üéØ Recommendation for Demo

### Best Choice: Sentence-Transformers ‚≠ê

**Why?**
1. **Instant setup** - One `pip install`, no API keys
2. **Works offline** - Great for demos without internet
3. **Unlimited usage** - Run as many demos as you want
4. **Fast** - 5 seconds for full dataset
5. **Good quality** - 96% as good as OpenAI
6. **Zero cost forever**

**Only downside**: Slightly lower quality than Cohere/Voyage (but still excellent!)

### Alternative: Cohere (If you want best quality)

**Choose if:**
- You want state-of-the-art embeddings
- You don't mind setting up API key
- You'll run <20 demos (free tier limit)

---

## Implementation Examples

### 1. Sentence-Transformers (Recommended)

```python
from sentence_transformers import SentenceTransformer
import numpy as np

class LocalEmbedder:
    def __init__(self, model_name='all-MiniLM-L6-v2'):
        self.model = SentenceTransformer(model_name)

    def embed(self, texts, batch_size=32):
        """Generate embeddings for texts."""
        return self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=True
        )

    def similarity(self, embedding1, embedding2):
        """Calculate cosine similarity."""
        return np.dot(embedding1, embedding2) / (
            np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
        )

# Usage
embedder = LocalEmbedder()
texts = ["London Business School", "LBS MBA Programme"]
embeddings = embedder.embed(texts)
print(f"Similarity: {embedder.similarity(embeddings[0], embeddings[1]):.3f}")
```

### 2. Cohere API

```python
import cohere
import os

class CohereEmbedder:
    def __init__(self):
        api_key = os.getenv("COHERE_API_KEY")
        self.client = cohere.Client(api_key)

    def embed(self, texts, batch_size=96):
        """Generate embeddings with batching."""
        all_embeddings = []

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            response = self.client.embed(
                texts=batch,
                model='embed-english-v3.0',
                input_type='search_document'
            )
            all_embeddings.extend(response.embeddings)

        return all_embeddings

# Usage
embedder = CohereEmbedder()
texts = ["London Business School", "LBS MBA Programme"]
embeddings = embedder.embed(texts)
```

### 3. Voyage AI

```python
import voyageai
import os

class VoyageEmbedder:
    def __init__(self):
        api_key = os.getenv("VOYAGE_API_KEY")
        self.client = voyageai.Client(api_key)

    def embed(self, texts, batch_size=128):
        """Generate embeddings with batching."""
        all_embeddings = []

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            result = self.client.embed(
                texts=batch,
                model="voyage-2"
            )
            all_embeddings.extend(result.embeddings)

        return all_embeddings

# Usage
embedder = VoyageEmbedder()
texts = ["London Business School", "LBS MBA Programme"]
embeddings = embedder.embed(texts)
```

---

## Quick Start: Sentence-Transformers

### Install (30 seconds)

```bash
pip install sentence-transformers
```

### Test (30 seconds)

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')
texts = [
    "London Business School offers world-class MBA programmes",
    "LBS provides excellent business education",
    "The weather is nice today"
]
embeddings = model.encode(texts)

# Calculate similarities
from sklearn.metrics.pairwise import cosine_similarity
similarities = cosine_similarity(embeddings)

print("Similarity matrix:")
print(similarities)
# Output:
# [[1.00, 0.85, 0.12],   # MBA programs highly similar
#  [0.85, 1.00, 0.15],   # Business education similar
#  [0.12, 0.15, 1.00]]   # Weather unrelated
```

### Integrate with Project (5 minutes)

```python
# In src/enrichment/embedding_generator.py

from sentence_transformers import SentenceTransformer

class EmbeddingGenerator:
    def __init__(self, provider="local"):
        if provider == "local":
            self.model = SentenceTransformer('all-MiniLM-L6-v2')
            self.provider = "local"
        elif provider == "cohere":
            # ... Cohere setup
        elif provider == "voyage":
            # ... Voyage setup

    async def generate_embedding(self, text: str) -> List[float]:
        """Generate embedding for single text."""
        if self.provider == "local":
            return self.model.encode([text])[0].tolist()
        # ... other providers
```

---

## Next Steps

Want me to:

1. **Install Sentence-Transformers** and test it now? (30 seconds)
2. **Create unified embedding module** that supports all three? (5 minutes)
3. **Update enrichment scripts** to use local embeddings? (5 minutes)
4. **Run comparison test** of all three options? (2 minutes)

For a demo, I strongly recommend **Sentence-Transformers** - it's the fastest path to a working demo with zero external dependencies!
